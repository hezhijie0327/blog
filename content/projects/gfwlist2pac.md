---
title: "GFWList2PAC - GFWListè½¬PACå·¥å…·"
description: "å°†GFWListæ•°æ®è½¬æ¢ä¸ºå¤šç§ä»£ç†è½¯ä»¶çš„PACæ–‡ä»¶ï¼Œæ”¯æŒè‡ªåŠ¨ä»£ç†é…ç½®"
date: "2020-12-06"
type: "personal"
tags: ["Shell", "GFWList", "PAC", "AutoProxy", "Clash", "Shadowrocket", "Surge"]
image: "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
link: "https://github.com/hezhijie0327/GFWList2PAC"
---

# GFWList2PAC - GFWListè½¬PACå·¥å…·

ä¸€ä¸ªä¸“é—¨ç”¨äºå°†GFWListæ•°æ®è½¬æ¢ä¸ºPACæ ¼å¼æ–‡ä»¶çš„å·¥å…·ï¼Œæ”¯æŒå¤šç§ä»£ç†è½¯ä»¶çš„è‡ªåŠ¨ä»£ç†é…ç½®ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

GFWList2PACåˆ©ç”¨GFWList2AGHé¡¹ç›®ç”Ÿæˆçš„æ•°æ®ï¼Œå°†å…¶è½¬æ¢ä¸ºå„ç§ä»£ç†è½¯ä»¶å¯ç”¨çš„PACå’Œè§„åˆ™æ–‡ä»¶ï¼Œä¸ºç”¨æˆ·æä¾›ä¾¿æ·çš„è‡ªåŠ¨ä»£ç†é…ç½®ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ”„ **å¤šæ ¼å¼è¾“å‡º** - æ”¯æŒPACã€AutoProxyã€Clashç­‰å¤šç§æ ¼å¼
- âš¡ **è‡ªåŠ¨æ›´æ–°** - åŸºäºGFWList2AGHçš„å®æ—¶æ•°æ®æ›´æ–°
- ğŸ¯ **æ™ºèƒ½ä¼˜åŒ–** - åŸŸåè§„åˆ™ä¼˜åŒ–å’Œå»é‡å¤„ç†
- ğŸ”§ **æ˜“äºéƒ¨ç½²** - ç®€å•çš„é…ç½®å’Œéƒ¨ç½²æµç¨‹
- ğŸ“Š **ç»Ÿè®¡åˆ†æ** - æä¾›è¯¦ç»†çš„åŸŸåå’Œè§„åˆ™ç»Ÿè®¡

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ•°æ®å¤„ç†æµç¨‹
```mermaid
graph TD
    A[GFWList2AGHæ•°æ®] --> B[åŸŸåæå–]
    B --> C[æ ¼å¼è½¬æ¢]
    C --> D[è§„åˆ™ä¼˜åŒ–]
    D --> E[å¤šæ ¼å¼è¾“å‡º]

    F[PACæ ¼å¼] --> E
    G[AutoProxyæ ¼å¼] --> E
    H[Clashè§„åˆ™] --> E
    I[Shadowrocketè§„åˆ™] --> E
    J[Surgeè§„åˆ™] --> E

    K[GitHub Actions] --> A
    K --> E
```

## ğŸ¨ æ ¸å¿ƒåŠŸèƒ½

### 1. PACç”Ÿæˆå™¨
```bash
#!/bin/bash
# pac_generator.sh - PACæ–‡ä»¶ç”Ÿæˆå™¨

# PACæ¨¡æ¿
PAC_TEMPLATE='function FindProxyForURL(url, host) {
    // GFWList based PAC file
    // Generated on: '$(date)'
    // Total rules: '$RULE_COUNT'

    // å°†åŸŸåè½¬æ¢ä¸ºå°å†™
    host = host.toLowerCase();
    url = url.toLowerCase();

    // æœ¬åœ°ç›´è¿
    if (isPlainHostName(host) ||
        shExpMatch(host, "*.local") ||
        shExpMatch(host, "localhost.*") ||
        shExpMatch(host, "127.*") ||
        shExpMatch(host, "10.*") ||
        shExpMatch(host, "172.16.*") ||
        shExpMatch(host, "172.17.*") ||
        shExpMatch(host, "172.18.*") ||
        shExpMatch(host, "172.19.*") ||
        shExpMatch(host, "172.2?.*") ||
        shExpMatch(host, "172.30.*") ||
        shExpMatch(host, "172.31.*") ||
        shExpMatch(host, "192.168.*")) {
        return "DIRECT";
    }

    // ä¸­å›½å¤§é™†ç›´è¿
    var cnDomains = [
'$CN_DOMAINS'
    ];

    for (var i = 0; i < cnDomains.length; i++) {
        if (dnsDomainIs(host, cnDomains[i])) {
            return "DIRECT";
        }
    }

    // ä»£ç†è§„åˆ™
    var proxyDomains = [
'$PROXY_DOMAINS'
    ];

    for (var i = 0; i < proxyDomains.length; i++) {
        if (dnsDomainIs(host, proxyDomains[i]) ||
            shExpMatch(host, "*" + proxyDomains[i])) {
            return "'$PROXY_SERVER'";
        }
    }

    // é»˜è®¤ç›´è¿
    return "DIRECT";
}'

# ç”ŸæˆPACæ–‡ä»¶
generate_pac() {
    local cn_domains_file=$1
    local proxy_domains_file=$2
    local proxy_server=${3:-"PROXY 127.0.0.1:7890; DIRECT"}
    local output_file=$4

    echo "Generating PAC file..."

    # å¤„ç†ä¸­å›½åŸŸå
    local cn_domains=""
    while IFS= read -r domain; do
        cn_domains+="        \"$domain\",\n"
    done < "$cn_domains_file"

    # å¤„ç†ä»£ç†åŸŸå
    local proxy_domains=""
    while IFS= read -r domain; do
        proxy_domains+="        \"$domain\",\n"
    done < "$proxy_domains_file"

    local rule_count=$(( $(wc -l < "$cn_domains_file") + $(wc -l < "$proxy_domains_file") ))

    # ç”ŸæˆPACæ–‡ä»¶
    echo -e "$PAC_TEMPLATE" | \
        sed "s/\$CN_DOMAINS/$cn_domains/g" | \
        sed "s/\$PROXY_DOMAINS/$proxy_domains/g" | \
        sed "s/\$PROXY_SERVER/$proxy_server/g" | \
        sed "s/\$RULE_COUNT/$rule_count/g" \
        > "$output_file"

    echo "PAC file generated: $output_file"
    echo "Total rules: $rule_count"
}
```

### 2. AutoProxyæ ¼å¼ç”Ÿæˆå™¨
```bash
#!/bin/bash
# autoproxy_generator.sh - AutoProxyæ ¼å¼ç”Ÿæˆå™¨

# AutoProxyæ–‡ä»¶å¤´
AUTOPROXY_HEADER='[AutoProxy 0.2.9]
! GFWList based AutoProxy rules
! Generated on: '$(date)'
! Total rules: '$RULE_COUNT'
!
! Format: https://autoproxy.org/en/index.html
!

! Direct rules for China domains
[DIRECT]
'

# AutoProxyä»£ç†è§„åˆ™
AUTOPROXY_PROXY='

! Proxy rules for blocked domains
[Proxy]
'

# ç”ŸæˆAutoProxyè§„åˆ™
generate_autoproxy() {
    local cn_domains_file=$1
    local proxy_domains_file=$2
    local output_file=$3

    echo "Generating AutoProxy rules..."

    # å†™å…¥æ–‡ä»¶å¤´
    echo -e "$AUTOPROXY_HEADER" > "$output_file"

    # æ·»åŠ ä¸­å›½ç›´è¿è§„åˆ™
    while IFS= read -r domain; do
        # å»é™¤é€šé…ç¬¦ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        echo "||$clean_domain" >> "$output_file"
    done < "$cn_domains_file"

    # æ·»åŠ ä»£ç†è§„åˆ™
    echo -e "$AUTOPROXY_PROXY" >> "$output_file"
    while IFS= read -r domain; do
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        echo "||$clean_domain" >> "$output_file"
        echo "||*.$clean_domain" >> "$output_file"
    done < "$proxy_domains_file"

    local rule_count=$(grep -c '^||' "$output_file")
    sed -i "s/\$RULE_COUNT/$rule_count/g" "$output_file"

    echo "AutoProxy rules generated: $output_file"
    echo "Total rules: $rule_count"
}
```

### 3. Clashè§„åˆ™ç”Ÿæˆå™¨
```bash
#!/bin/bash
# clash_generator.sh - Clashè§„åˆ™ç”Ÿæˆå™¨

# Clash YAMLæ¨¡æ¿
CLASH_TEMPLATE='# Clash rules based on GFWList
# Generated on: '$(date)'
# Total rules: '$RULE_COUNT'
#

mixed-port: 7890
allow-lan: false
mode: rule
log-level: info

dns:
  enable: true
  ipv6: false
  nameserver:
    - 223.5.5.5
    - 119.29.29.29
  fallback:
    - 1.1.1.1
    - 8.8.8.8

proxies: []

proxy-groups:
- name: "Proxy"
  type: select
  proxies:
    - DIRECT
- name: "Default"
  type: select
  proxies:
    - Proxy
    - DIRECT

rules:
'$DOMAIN_RULES'
  - MATCH,Default
'

# ç”ŸæˆClashè§„åˆ™
generate_clash() {
    local cn_domains_file=$1
    local proxy_domains_file=$2
    local output_file=$3

    echo "Generating Clash rules..."

    local domain_rules=""
    local rule_count=0

    # æ·»åŠ ä¸­å›½ç›´è¿è§„åˆ™
    while IFS= read -r domain; do
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        domain_rules+="  - DOMAIN-SUFFIX,$clean_domain,DIRECT\n"
        ((rule_count++))
    done < "$cn_domains_file"

    # æ·»åŠ ä»£ç†è§„åˆ™
    while IFS= read -r domain; do
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        domain_rules+="  - DOMAIN-SUFFIX,$clean_domain,Proxy\n"
        domain_rules+="  - DOMAIN-KEYWORD,$clean_domain,Proxy\n"
        ((rule_count += 2))
    done < "$proxy_domains_file"

    # ç”ŸæˆClashé…ç½®æ–‡ä»¶
    echo -e "$CLASH_TEMPLATE" | \
        sed "s/\$DOMAIN_RULES/$domain_rules/g" | \
        sed "s/\$RULE_COUNT/$rule_count/g" \
        > "$output_file"

    echo "Clash rules generated: $output_file"
    echo "Total rules: $rule_count"
}
```

### 4. Surgeè§„åˆ™ç”Ÿæˆå™¨
```bash
#!/bin/bash
# surge_generator.sh - Surgeè§„åˆ™ç”Ÿæˆå™¨

# Surgeè§„åˆ™æ¨¡æ¿
SURGE_TEMPLATE='[General]
loglevel = notify
interface = 127.0.0.1
skip-proxy = 127.0.0.1, 192.168.0.0/16, 10.0.0.0/8, 172.16.0.0/12, 100.64.0.0/10, localhost, *.local

[Rule]
# GFWList based Surge rules
# Generated on: '$(date)'
# Total rules: '$RULE_COUNT'
#

'

# ç”ŸæˆSurgeè§„åˆ™
generate_surge() {
    local cn_domains_file=$1
    local proxy_domains_file=$2
    local output_file=$3

    echo "Generating Surge rules..."

    # å†™å…¥æ–‡ä»¶å¤´
    echo -e "$SURGE_TEMPLATE" > "$output_file"

    # æ·»åŠ ä¸­å›½ç›´è¿è§„åˆ™
    while IFS= read -r domain; do
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        echo "DOMAIN-SUFFIX,$clean_domain,DIRECT" >> "$output_file"
    done < "$cn_domains_file"

    # æ·»åŠ ä»£ç†è§„åˆ™
    while IFS= read -r domain; do
        clean_domain=$(echo "$domain" | sed 's/\*\./\./g' | sed 's/^\*\.//g')
        echo "DOMAIN-SUFFIX,$clean_domain,Proxy" >> "$output_file"
        echo "DOMAIN-KEYWORD,$clean_domain,Proxy" >> "$output_file"
    done < "$proxy_domains_file"

    # æ·»åŠ é»˜è®¤è§„åˆ™
    echo "FINAL,DIRECT" >> "$output_file"

    local rule_count=$(grep -c '^DOMAIN' "$output_file")
    sed -i "s/\$RULE_COUNT/$rule_count/g" "$output_file"

    echo "Surge rules generated: $output_file"
    echo "Total rules: $rule_count"
}
```

### 5. æ•°æ®æºåŒæ­¥å™¨
```bash
#!/bin/bash
# sync_data.sh - æ•°æ®æºåŒæ­¥

# åŒæ­¥GFWList2AGHæ•°æ®
sync_gfwlist_data() {
    local base_url=${1:-"https://raw.githubusercontent.com/hezhijie0327/GFWList2AGH/main"}
    local output_dir="data"

    echo "Syncing data from GFWList2AGH..."

    mkdir -p "$output_dir"

    # ä¸‹è½½ä¸­å›½åŸŸåç™½åå•
    if curl -s "$base_url/cnacc.txt" > "$output_dir/cn_domains.txt"; then
        echo "âœ… Downloaded CN domains: $(wc -l < "$output_dir/cn_domains.txt")"
    else
        echo "âŒ Failed to download CN domains"
        return 1
    fi

    # ä¸‹è½½GFWåˆ—è¡¨
    if curl -s "$base_url/gfwlist.txt" > "$output_dir/proxy_domains.txt"; then
        echo "âœ… Downloaded GFW domains: $(wc -l < "$output_dir/proxy_domains.txt")"
    else
        echo "âŒ Failed to download GFW domains"
        return 1
    fi

    # æ•°æ®æ¸…ç†
    clean_domain_data "$output_dir/cn_domains.txt"
    clean_domain_data "$output_dir/proxy_domains.txt"

    echo "âœ… Data synchronization completed"
}

# æ¸…ç†åŸŸåæ•°æ®
clean_domain_data() {
    local file=$1

    # å»é™¤æ³¨é‡Šå’Œç©ºè¡Œ
    grep -v '^#' "$file" | grep -v '^$' | \
    # è½¬æ¢ä¸ºå°å†™
    tr '[:upper:]' '[:lower:]' | \
    # å»é™¤é‡å¤
    sort -u | \
    # éªŒè¯åŸŸåæ ¼å¼
    grep -E '^[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$' \
    > "$file.tmp"

    mv "$file.tmp" "$file"
}
```

## ğŸ”§ è‡ªåŠ¨åŒ–å·¥ä½œæµ

### GitHub Actionsé…ç½®
```yaml
# .github/workflows/generate-pac.yml
name: Generate PAC Files

on:
  schedule:
    - cron: '0 */6 * * *'  # æ¯6å°æ—¶æ›´æ–°
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  generate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl wget

      - name: Sync data from GFWList2AGH
        run: |
          chmod +x scripts/*.sh
          ./scripts/sync_data.sh

      - name: Generate PAC files
        run: |
          # ç”Ÿæˆæ ‡å‡†PACæ–‡ä»¶
          ./scripts/pac_generator.sh \
            data/cn_domains.txt \
            data/proxy_domains.txt \
            "PROXY 127.0.0.1:7890; DIRECT" \
            output/gfwlist.pac

          # ç”ŸæˆAutoProxyè§„åˆ™
          ./scripts/autoproxy_generator.sh \
            data/cn_domains.txt \
            data/proxy_domains.txt \
            output/gfwlist_autoproxy.txt

          # ç”ŸæˆClashè§„åˆ™
          ./scripts/clash_generator.sh \
            data/cn_domains.txt \
            data/proxy_domains.txt \
            output/clash_rules.yaml

          # ç”ŸæˆSurgeè§„åˆ™
          ./scripts/surge_generator.sh \
            data/cn_domains.txt \
            data/proxy_domains.txt \
            output/surge_rules.txt

      - name: Generate Shadowrocket rules
        run: |
          # Shadowrocketä½¿ç”¨ç®€åŒ–ç‰ˆè§„åˆ™
          echo "# Shadowrocket rules" > output/shadowrocket.conf
          echo "# Generated on $(date)" >> output/shadowrocket.conf

          # ä¸­å›½ç›´è¿
          while IFS= read -r domain; do
            echo "DOMAIN-SUFFIX,$domain,DIRECT" >> output/shadowrocket.conf
          done < data/cn_domains.txt

          # ä»£ç†è§„åˆ™
          while IFS= read -r domain; do
            echo "DOMAIN-SUFFIX,$domain,Proxy" >> output/shadowrocket.conf
          done < data/proxy_domains.txt

          echo "MATCH,DIRECT" >> output/shadowrocket.conf

      - name: Generate statistics
        run: |
          echo "# Statistics" > output/stats.txt
          echo "Generated on: $(date)" >> output/stats.txt
          echo "CN domains: $(wc -l < data/cn_domains.txt)" >> output/stats.txt
          echo "Proxy domains: $(wc -l < data/proxy_domains.txt)" >> output/stats.txt
          echo "Total rules: $(( $(wc -l < data/cn_domains.txt) + $(wc -l < data/proxy_domains.txt) ))" >> output/stats.txt

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add output/
          git diff --staged --quiet || git commit -m "Auto update PAC files - $(date +'%Y-%m-%d %H:%M:%S')"
          git push

      - name: Create release
        if: contains(github.event.head_commit.message, '[release]')
        run: |
          tag_name="v$(date +'%Y%m%d-%H%M')"
          gh release create "$tag_name" \
            --title "PAC Files $tag_name" \
            --generate-notes \
            output/*.pac output/*.txt output/*.yaml output/*.conf
```

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/hezhijie0327/GFWList2PAC.git
cd GFWList2PAC

# åŒæ­¥æ•°æ®
chmod +x scripts/*.sh
./scripts/sync_data.sh

# ç”ŸæˆPACæ–‡ä»¶
./scripts/pac_generator.sh \
  data/cn_domains.txt \
  data/proxy_domains.txt \
  "PROXY 127.0.0.1:7890; DIRECT" \
  gfwlist.pac

# ç”Ÿæˆå…¶ä»–æ ¼å¼
./scripts/autoproxy_generator.sh data/cn_domains.txt data/proxy_domains.txt gfwlist_autoproxy.txt
./scripts/clash_generator.sh data/cn_domains.txt data/proxy_domains.txt clash_rules.yaml
./scripts/surge_generator.sh data/cn_domains.txt data/proxy_domains.txt surge_rules.txt
```

### æµè§ˆå™¨PACé…ç½®
1. ä¸‹è½½ç”Ÿæˆçš„PACæ–‡ä»¶
2. åœ¨æµè§ˆå™¨ä¸­è®¾ç½®è‡ªåŠ¨ä»£ç†é…ç½®
3. è¾“å…¥PACæ–‡ä»¶çš„URLæˆ–æœ¬åœ°è·¯å¾„

### Clashå¯¼å…¥è§„åˆ™
```yaml
# åœ¨Clashé…ç½®ä¸­å¯¼å…¥è§„åˆ™æ–‡ä»¶
rules:
  - RULE-SET,gfwlist,Proxy
  - RULE-SET,cndirect,DIRECT
  - MATCH,DIRECT

rule-providers:
  gfwlist:
    type: file
    path: ./clash_rules.yaml
  cndirect:
    type: file
    path: ./cn_rules.yaml
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### è§„åˆ™ä¼˜åŒ–ç®—æ³•
```bash
#!/bin/bash
# optimize_rules.sh - è§„åˆ™ä¼˜åŒ–

# åŸŸåå»é‡å’Œåˆå¹¶
optimize_domains() {
    local input_file=$1
    local output_file=$2

    echo "Optimizing domain rules..."

    # æå–æ‰€æœ‰åŸŸå
    grep -E '^\|\|.*\^' "$input_file" | \
    sed 's/^\|\|//g' | sed 's/\^$//g' | \
    sort -u > "$output_file"

    # åˆå¹¶å­åŸŸå
    awk '{
        parts = split($0, domains, ".")
        if (parts >= 2) {
            domain = domains[parts-1] "." domains[parts]
            print domain
        }
    }' "$output_file" | sort -u >> "$output_file.tmp"

    # å»é‡
    sort -u "$output_file.tmp" > "$output_file"
    rm -f "$output_file.tmp"

    echo "Optimization completed: $(wc -l < "$output_file") unique domains"
}

# è§„åˆ™å‹ç¼©
compress_rules() {
    local input_file=$1
    local output_file=$2

    echo "Compressing rules..."

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆå¹¶ç›¸ä¼¼è§„åˆ™
    python3 << EOF
import re

def compress_rules(rules):
    compressed = []
    patterns = {}

    for rule in rules:
        # æå–åŸŸåæ¨¡å¼
        match = re.match(r'\|\|(.+)\^', rule)
        if match:
            domain = match.group(1)
            # æŸ¥æ‰¾å¯èƒ½çš„çˆ¶åŸŸå
            parts = domain.split('.')
            for i in range(1, len(parts)):
                parent = '.'.join(parts[i:])
                if parent in patterns:
                    patterns[parent].append(domain)
                else:
                    patterns[parent] = [domain]

    # ç”Ÿæˆå‹ç¼©è§„åˆ™
    for parent, children in patterns.items():
        if len(children) > 3:  # å¦‚æœæœ‰å¤šä¸ªå­åŸŸåï¼Œä½¿ç”¨çˆ¶åŸŸåè§„åˆ™
            compressed.append(f"||{parent}^")
        else:
            compressed.extend([f"||{child}^" for child in children])

    return compressed

# è¯»å–è§„åˆ™
with open('$input_file', 'r') as f:
    rules = [line.strip() for line in f if line.strip()]

# å‹ç¼©è§„åˆ™
compressed = compress_rules(rules)

# å†™å…¥ç»“æœ
with open('$output_file', 'w') as f:
    for rule in compressed:
        f.write(rule + '\n')

print(f"Compressed {len(rules)} rules to {len(compressed)} rules")
EOF
}
```

## ğŸ”® é¡¹ç›®ä»·å€¼

### æŠ€æœ¯ä»·å€¼
- **å¤šæ ¼å¼æ”¯æŒ** - ç»Ÿä¸€çš„æ•°æ®æºç”Ÿæˆå¤šç§ä»£ç†æ ¼å¼
- **è‡ªåŠ¨åŒ–æ›´æ–°** - å®æ—¶åŒæ­¥GFWList2AGHçš„æœ€æ–°æ•°æ®
- **è§„åˆ™ä¼˜åŒ–** - æ™ºèƒ½çš„è§„åˆ™å»é‡å’Œå‹ç¼©ç®—æ³•
- **å¹¿æ³›å…¼å®¹** - æ”¯æŒä¸»æµä»£ç†è½¯ä»¶å’Œå¹³å°

### å®ç”¨ä»·å€¼
- **é…ç½®ç®€åŒ–** - ä¸€é”®ç”Ÿæˆå„ç§æ ¼å¼çš„ä»£ç†è§„åˆ™
- **ç»´æŠ¤ä¾¿åˆ©** - è‡ªåŠ¨åŒ–çš„æ›´æ–°å’Œç»´æŠ¤æµç¨‹
- **æ€§èƒ½æå‡** - ä¼˜åŒ–åçš„è§„åˆ™å‡å°‘åŒ¹é…æ—¶é—´
- **ç”¨æˆ·å‹å¥½** - æä¾›è¯¦ç»†çš„ä½¿ç”¨æ–‡æ¡£å’Œç¤ºä¾‹

### ç¤¾åŒºå½±å“
- â­ **48+ Stars** - è·å¾—GitHubç¤¾åŒºå¹¿æ³›è®¤å¯
- ğŸŒ **å…¨çƒä½¿ç”¨** - æ”¯æŒå…¨çƒç”¨æˆ·çš„ç½‘ç»œè®¿é—®éœ€æ±‚
- ğŸ”„ **æŒç»­æ›´æ–°** - è·Ÿéšç½‘ç»œç¯å¢ƒå˜åŒ–åŠæ—¶ç»´æŠ¤
- ğŸ“š **çŸ¥è¯†åˆ†äº«** - æ¨å¹¿ç½‘ç»œè‡ªç”±è®¿é—®æŠ€æœ¯

---

**é¡¹ç›®é“¾æ¥**: [GitHub Repository](https://github.com/hezhijie0327/GFWList2PAC)

**æŠ€æœ¯æ ˆ**: Shell Script | PAC | AutoProxy | Clash | Shadowrocket | Surge | Network Automation